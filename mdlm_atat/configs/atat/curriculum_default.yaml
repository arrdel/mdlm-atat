# Phase 1C: Curriculum Default Schedule (0.3, 0.7)
# 
# This is the optimal curriculum schedule found in Phase 1B masking strategy ablation.
# It provides a balanced progression from easy to hard tokens.
#
# Boundary Definitions:
#   - Easy stage:   0 - 150K steps (30% of total)
#   - Medium stage: 150K - 350K steps (40% of total)
#   - Hard stage:   350K - 500K steps (30% of total)
#
# Expected Performance:
#   - PPL: 39.03 (baseline)
#   - Easy test:   2.8
#   - Medium test: 2.2
#   - Hard test:   1.8
#
# Curriculum Progression:
#   - Easy: All tokens masked equally, learn basic patterns
#   - Medium: Gradual importance integration, blend easy/hard strategies
#   - Hard: Focus on important tokens, maximize gradient signal
#
# The default schedule is used as the comparison baseline for Phase 1C.
# It represents the sweet spot between rushed (early) and delayed (late) progression.

name: curriculum_default

model:
  # Use balanced masking strategy from Phase 1B
  masking_strategy: balanced
  model_name: mdlm_default
  model_type: dit_diffusion
  
training:
  max_steps: 5000  # DEBUG: 5K steps
  
  # Curriculum boundaries - define stage transitions
  curriculum_schedule:
    type: default
    # Stage 1: Easy (0-150K) - learn all tokens equally
    easy_boundary: 150000
    # Stage 2: Medium (150K-350K) - gradual importance integration
    medium_boundary: 350000
    # Stage 3: Hard (350K-500K) - focus on important tokens
    hard_boundary: 500000
    
    # Per-stage masking configuration
    stages:
      easy:
        step_range: [0, 150000]
        description: "Learn all tokens equally"
        masking_config:
          uniform_mask_ratio: 1.0
          importance_weight: 0.0
          
      medium:
        step_range: [150000, 350000]
        description: "Gradual importance integration"
        masking_config:
          uniform_mask_ratio: 0.5
          importance_weight: 0.5
          transition_type: linear
          
      hard:
        step_range: [350000, 500000]
        description: "Focus on important tokens"
        masking_config:
          uniform_mask_ratio: 0.0
          importance_weight: 1.0

  # Shared training configuration from Phase 1B
  batch_size: 32
  learning_rate: 0.0001
  warmup_steps: 10000
  
  # Use balanced masking from Phase 1B
  masking:
    strategy: balanced
    formula: "g_bal(i,t) = (1-t)*g_inv + t*g_prop"
    
    # Inverse masking (preserve important tokens)
    inverse_mask:
      weight: 0.7
      preserve_ratio: 0.7
      description: "Always preserve important tokens"
    
    # Proportional masking (importance-based)
    proportional_mask:
      weight: 0.3
      importance_ratio: 0.7
      time_decay: 0.3
      description: "Always mask important more"
    
    # Curriculum-driven balance
    curriculum_balance:
      early_emphasis: inverse  # Start by preserving important
      late_emphasis: proportional  # Shift to importance-based
      transition_type: linear

evaluation:
  eval_steps: 5000
  eval_per_stage: true
  
  # Collect per-stage metrics
  metrics:
    by_stage:
      easy: [ppl, loss, gradient_norm]
      medium: [ppl, loss, gradient_norm]
      hard: [ppl, loss, gradient_norm]

  # Expected results
  expected:
    ppl: 39.03
    loss:
      easy: 2.8
      medium: 2.2
      hard: 1.8

# Logging and checkpointing
logging:
  log_frequency: 100
  checkpoint_frequency: 50000
  save_curriculum_boundaries: true
  
  boundary_tracking:
    track_easy_to_medium: 150000
    track_medium_to_hard: 350000

# This is the reference schedule for Phase 1C
# Compare against:
# - early (0.2, 0.6): 39.54 PPL (+0.51)
# - late (0.35, 0.8): 39.71 PPL (+0.68)
# - no_curriculum: 40.25 PPL (+1.22)
