# ðŸŽ‰ Full Production Training - Ready to Go!

## âœ… Complete Summary

Your MDLM+ATAT project is **fully configured and ready for 500k-step production training**.

---

## ðŸŽ¯ Answer: Dataset Splitting

### **NO - You Don't Need Manual Dataset Splitting** âœ“

**Why?** HuggingFace datasets include automatic train/validation splits:

```
OpenWebText (40GB) 
â”œâ”€â”€ Train Split: ~38GB (automatically selected)
â””â”€â”€ Validation Split: ~2GB (automatically selected)
```

The framework automatically uses:
- `mode='train'` â†’ Uses OpenWebText train split (~38GB)
- `mode='validation'` â†’ Uses OpenWebText validation split (~2GB)

**Your config already handles this:**
```yaml
data:
  train: openwebtext      # Automatically uses train split
  valid: openwebtext      # Automatically uses validation split
```

---

## ðŸš€ 3-Step Quick Start

### Step 1: Download Dataset (One-Time, ~30 mins)
```bash
cd /home/adelechinda/home/projects/mdlm
python mdlm_atat/scripts/download_datasets.py --datasets openwebtext
```
âœ“ Downloads 40GB to `/media/scratch/adele/mdlm_fresh/data_cache/`

### Step 2: Configuration Ready! âœ“
```bash
# Already created and fully configured:
mdlm_atat/configs/atat/production_training.yaml
```
- Model: Full BERT-scale DiT with ATAT
- Batch size: 24 (4 per GPU Ã— 6 GPUs)
- Steps: 500,000
- All ATAT components enabled

### Step 3: Start Training (1-2 weeks continuous)
```bash
python mdlm_atat/scripts/train_atat.py \
  --config-name atat/production_training \
  --max-steps 500000
```

---

## ðŸ“Š What You Have

| Component | Status | Details |
|-----------|--------|---------|
| Code | âœ… Ready | 103 files on GitHub |
| Configuration | âœ… Ready | Production config created |
| Dataset Handling | âœ… Ready | Auto-splits configured |
| Training Script | âœ… Ready | PyTorch Lightning trainer |
| Monitoring | âœ… Ready | Logs, checkpoints, metrics |
| Auto-resume | âœ… Ready | Continues from latest checkpoint |
| Documentation | âœ… Ready | 5+ comprehensive guides |

---

## ðŸ“ˆ Training Overview

### Configuration Details
```yaml
model:
  - Type: Discrete Masked Diffusion (MDLM)
  - Enhancement: ATAT (Adaptive Training)
  - Architecture: DIT (Diffusion Transformer)
  - Size: Full BERT-scale (768D, 12 layers)
  - Sequence Length: 1024 tokens

training:
  - Batch Size: 24 global (4 per GPU)
  - Learning Rate: 1e-4 with cosine warmup
  - Total Steps: 500,000
  - Precision: bf16 (mixed precision)
  - Grad Clipping: 1.0
  - EMA: 0.9999

curriculum:
  - Type: Linear progression
  - Warmup: 5,000 steps (1% of total)
  - Easy Tokens: 30% early on
  - Hard Tokens: 30% throughout
  - Dynamic: Adaptive adjustment disabled

data:
  - Source: OpenWebText
  - Train: 38GB
  - Validation: 2GB
  - Tokenizer: GPT-2
  - Block Size: 1024 tokens
```

### Timeline
- **Data Download**: ~30 minutes (one-time)
- **Training**: 1-2 weeks on 6x RTX 4090
- **Checkpoints**: Every 5,000 steps (~34 checkpoints)
- **Validation**: Every 1,000 steps
- **Total Data Processed**: 500k Ã— 1024 = 512M tokens

---

## ðŸ“‚ Files Added

### Documentation
âœ“ **PRODUCTION_TRAINING_SETUP.md**
  - Complete step-by-step guide
  - Dataset splitting explanation
  - Monitoring instructions
  - Troubleshooting guide

âœ“ **GITHUB_LIVE.md**
  - Repository overview
  - Quick reference

âœ“ **FINAL_SETUP.md**
  - GitHub setup guide

### Configuration
âœ“ **mdlm_atat/configs/atat/production_training.yaml**
  - Production-ready configuration
  - All ATAT components enabled
  - Optimized hyperparameters
  - Ready to use immediately

---

## ðŸ”„ How Auto-Resume Works

**Automatic Checkpoint Detection:**
```
Training interrupted at step 250,000?
â†“
Just run the same command again:
python mdlm_atat/scripts/train_atat.py --config-name atat/production_training --max-steps 500000
â†“
Framework automatically:
âœ“ Detects latest checkpoint
âœ“ Loads model weights and optimizer state
âœ“ Resumes from step 250,000
âœ“ Continues to step 500,000
âœ“ No data re-processing
â†“
Total result: Uninterrupted 500k step training
```

---

## ðŸ“Š Monitoring During Training

### GPU Usage (Real-time)
```bash
watch -n 1 nvidia-smi
```
Should show 6 GPUs at ~90%+ utilization

### Training Progress
```bash
tail -f /media/scratch/adele/mdlm_fresh/logs/training_*.log
```
Shows: loss, validation metrics, checkpoint saving

### Checkpoint Status
```bash
ls -lt /media/scratch/adele/mdlm_fresh/checkpoints/ | head -10
```
Shows: Recent checkpoints sorted by date

---

## âš™ï¸ Key Configuration Parameters

### Model
- `hidden_size: 768` - Full BERT dimensions
- `n_blocks: 12` - 12 transformer blocks
- `n_heads: 12` - 12 attention heads
- `importance_hidden_dim: 256` - Importance estimator
- `use_importance: true` - Enable importance prediction
- `use_adaptive_masking: true` - Enable adaptive masking
- `use_curriculum: true` - Enable curriculum learning

### Training
- `max_steps: 500000` - 500,000 steps total
- `learning_rate: 1e-4` - 0.0001 learning rate
- `warmup_steps: 5000` - 5,000 step warmup (1% of total)
- `grad_clip_norm: 1.0` - Gradient clipping to 1.0
- `save_interval: 5000` - Save every 5,000 steps
- `val_check_interval: 1000` - Validate every 1,000 steps

### Data
- `batch_size: 4` - Per-GPU batch size
- `global_batch_size: 24` - 4 Ã— 6 GPUs = 24
- `num_workers: 8` - Parallel data loading
- `length: 1024` - Sequence length (tokens)

---

## ðŸŽ¯ Expected Outcomes

### Training Metrics
- **Loss**: Should decrease monotonically (with curriculum)
- **Validation Loss**: Should stabilize or improve
- **GPU Utilization**: 85-95% consistently
- **Memory**: ~20GB per GPU (out of 24GB)

### Checkpoints Generated
- **Number**: ~100 (every 5,000 steps)
- **Size**: ~2-3GB per checkpoint (model weights)
- **Total Storage**: ~250-300GB (keep 5 best)

### Time Estimate
- **Total Steps**: 500,000
- **Speed**: ~200-300 steps/hour
- **Total Time**: ~1,700-2,500 hours
- **Wall-clock**: 7-14 days continuous on 6 GPUs

---

## ðŸ†˜ Common Issues & Solutions

### Issue: "CUDA out of memory"
**Solution**: Reduce batch_size (4 â†’ 2 per GPU) in config

### Issue: "Dataset not found"
**Solution**: Download first
```bash
python mdlm_atat/scripts/download_datasets.py --datasets openwebtext
```

### Issue: "Training seems stuck"
**Solution**: Check GPU utilization
```bash
nvidia-smi  # Should show all 6 GPUs at >80%
```

### Issue: "Slow data loading"
**Solution**: Increase num_workers in config (8 â†’ 16)

### Issue: "Out of disk space"
**Solution**: Check available space
```bash
df -h /media/scratch/adele/
```
Need: 40GB data + 300GB checkpoints = 340GB minimum

---

## ðŸ“‹ Pre-Training Checklist

Before you start:
```
â–¡ 40GB free space available
â–¡ 300GB available for checkpoints
â–¡ All 6 RTX 4090 GPUs healthy
â–¡ CUDA 11.8+ installed
â–¡ PyTorch 2.0+ installed
â–¡ PyTorch Lightning installed
â–¡ Hydra installed
â–¡ transformers library installed

Commands to verify:
nvidia-smi              # Check GPUs
python -c "import torch; print(torch.__version__)"
python -c "import lightning; print(lightning.__version__)"
python -c "import hydra; print(hydra.__version__)"
```

---

## ðŸš€ Let's Start!

### Final Command to Start Training
```bash
cd /home/adelechinda/home/projects/mdlm

# Step 1: Download (one-time, skip if already done)
python mdlm_atat/scripts/download_datasets.py --datasets openwebtext

# Step 2: Start training!
python mdlm_atat/scripts/train_atat.py \
  --config-name atat/production_training \
  --max-steps 500000

# Or with no confirmation prompts:
python mdlm_atat/scripts/train_atat.py \
  --config-name atat/production_training \
  --max-steps 500000 \
  --no-confirm
```

### Monitor in Another Terminal
```bash
# Terminal 1: GPU usage
watch -n 1 nvidia-smi

# Terminal 2: Training logs
tail -f /media/scratch/adele/mdlm_fresh/logs/training_*.log

# Terminal 3: Checkpoint status
watch ls -lt /media/scratch/adele/mdlm_fresh/checkpoints/ | head -10
```

---

## ðŸ“š Documentation Files

All in your GitHub repository:
1. **README.md** - Project overview
2. **PRODUCTION_TRAINING_SETUP.md** - This guide
3. **GITHUB_LIVE.md** - Repository info
4. **FINAL_SETUP.md** - GitHub setup
5. **docs/** - Architecture diagrams (13 files)
6. **docs/archived_reports/** - Technical reports

---

## ðŸŽ¯ Summary

âœ… **Dataset Splitting**: Automatic (no manual work needed)
âœ… **Configuration**: Production-ready (pre-configured)
âœ… **Data**: 40GB OpenWebText ready to download
âœ… **Training**: 500k steps, 1-2 weeks on 6 GPUs
âœ… **Monitoring**: Full logging and checkpointing
âœ… **Auto-resume**: If interrupted, just re-run
âœ… **Documentation**: Comprehensive guides included

**You're ready to train!** ðŸš€

```bash
# Download & train:
python mdlm_atat/scripts/download_datasets.py --datasets openwebtext
python mdlm_atat/scripts/train_atat.py --config-name atat/production_training --max-steps 500000
```

Good luck! ðŸŽ‰
